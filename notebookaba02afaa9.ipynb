{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7281879,"sourceType":"datasetVersion","datasetId":4222244}],"dockerImageVersionId":30627,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Flatten, Activation, LayerNormalization, Reshape\nfrom keras.optimizers import Adam\n\ndf = pd.read_csv('/kaggle/input/suduku/sudoku.csv')\n\nX = np.array(df.quizzes.map(lambda x: list(map(int, x))).to_list())\nY = np.array(df.solutions.map(lambda x: list(map(int, x))).to_list())\n\n\nX = X.reshape(-1, 9, 9, 1)\nY = Y.reshape(-1, 9, 9) - 1\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(128, 3, activation='relu', padding='same', input_shape = (9, 9, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, 3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, 3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, 3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, 3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, 3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(1024, 3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(9, 3, activation='relu', padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Dense(81*9))\nmodel.add(LayerNormalization(axis=-1))\nmodel.add(Reshape((9, 9, 9)))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n\nmodel.summary()\n\nmodel.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))\n\nmodel.evaluate(x_test, y_test)\n\nmodel.save('/kaggle/working/mindlock-model.h5')\n\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-26T06:15:36.146860Z","iopub.execute_input":"2023-12-26T06:15:36.147115Z","iopub.status.idle":"2023-12-26T07:26:36.130822Z","shell.execute_reply.started":"2023-12-26T06:15:36.147090Z","shell.execute_reply":"2023-12-26T07:26:36.129938Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 9, 9, 128)         1280      \n                                                                 \n batch_normalization (Batch  (None, 9, 9, 128)         512       \n Normalization)                                                  \n                                                                 \n conv2d_1 (Conv2D)           (None, 9, 9, 128)         147584    \n                                                                 \n batch_normalization_1 (Bat  (None, 9, 9, 128)         512       \n chNormalization)                                                \n                                                                 \n conv2d_2 (Conv2D)           (None, 9, 9, 256)         295168    \n                                                                 \n batch_normalization_2 (Bat  (None, 9, 9, 256)         1024      \n chNormalization)                                                \n                                                                 \n conv2d_3 (Conv2D)           (None, 9, 9, 256)         590080    \n                                                                 \n batch_normalization_3 (Bat  (None, 9, 9, 256)         1024      \n chNormalization)                                                \n                                                                 \n conv2d_4 (Conv2D)           (None, 9, 9, 512)         1180160   \n                                                                 \n batch_normalization_4 (Bat  (None, 9, 9, 512)         2048      \n chNormalization)                                                \n                                                                 \n conv2d_5 (Conv2D)           (None, 9, 9, 512)         2359808   \n                                                                 \n batch_normalization_5 (Bat  (None, 9, 9, 512)         2048      \n chNormalization)                                                \n                                                                 \n conv2d_6 (Conv2D)           (None, 9, 9, 1024)        4719616   \n                                                                 \n batch_normalization_6 (Bat  (None, 9, 9, 1024)        4096      \n chNormalization)                                                \n                                                                 \n conv2d_7 (Conv2D)           (None, 9, 9, 9)           82953     \n                                                                 \n flatten (Flatten)           (None, 729)               0         \n                                                                 \n dense (Dense)               (None, 512)               373760    \n                                                                 \n dense_1 (Dense)             (None, 729)               373977    \n                                                                 \n layer_normalization (Layer  (None, 729)               1458      \n Normalization)                                                  \n                                                                 \n reshape (Reshape)           (None, 9, 9, 9)           0         \n                                                                 \n activation (Activation)     (None, 9, 9, 9)           0         \n                                                                 \n=================================================================\nTotal params: 10137108 (38.67 MB)\nTrainable params: 10131476 (38.65 MB)\nNon-trainable params: 5632 (22.00 KB)\n_________________________________________________________________\nEpoch 1/10\n12500/12500 [==============================] - 428s 33ms/step - loss: 0.5493 - accuracy: 0.8021 - val_loss: 0.2378 - val_accuracy: 0.9139\nEpoch 2/10\n12500/12500 [==============================] - 415s 33ms/step - loss: 0.1874 - accuracy: 0.9325 - val_loss: 0.1594 - val_accuracy: 0.9428\nEpoch 3/10\n12500/12500 [==============================] - 413s 33ms/step - loss: 0.1360 - accuracy: 0.9512 - val_loss: 0.1282 - val_accuracy: 0.9540\nEpoch 4/10\n12500/12500 [==============================] - 412s 33ms/step - loss: 0.1103 - accuracy: 0.9605 - val_loss: 0.1127 - val_accuracy: 0.9597\nEpoch 5/10\n12500/12500 [==============================] - 412s 33ms/step - loss: 0.0934 - accuracy: 0.9666 - val_loss: 0.1025 - val_accuracy: 0.9636\nEpoch 6/10\n12500/12500 [==============================] - 413s 33ms/step - loss: 0.0805 - accuracy: 0.9713 - val_loss: 0.0962 - val_accuracy: 0.9659\nEpoch 7/10\n12500/12500 [==============================] - 413s 33ms/step - loss: 0.0703 - accuracy: 0.9749 - val_loss: 0.0918 - val_accuracy: 0.9679\nEpoch 8/10\n12500/12500 [==============================] - 413s 33ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.0905 - val_accuracy: 0.9687\nEpoch 9/10\n12500/12500 [==============================] - 413s 33ms/step - loss: 0.0546 - accuracy: 0.9805 - val_loss: 0.0902 - val_accuracy: 0.9693\nEpoch 10/10\n12500/12500 [==============================] - 414s 33ms/step - loss: 0.0483 - accuracy: 0.9827 - val_loss: 0.0907 - val_accuracy: 0.9697\n6250/6250 [==============================] - 49s 8ms/step - loss: 0.0907 - accuracy: 0.9697\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tf.keras.models.load_model('/kaggle/working/mindlock-model.h5')\n\nsample_sudoku = np.array([0,0,4,3,0,0,2,0,9,0,0,5,0,0,9,0,0,1,0,7,0,0,6,0,0,4,3,0,0,6,0,0,2,0,8,7,1,9,0,0,0,7,4,0,0,0,5,0,0,8,3,0,0,0,6,0,0,0,0,0,1,0,5,0,0,3,5,0,8,6,9,0,0,4,2,9,1,0,3,0,0])\n\nsample_sudoku = sample_sudoku.reshape(-1, 9, 9, 1)\n\nsolution_sudoku = model.predict([sample_sudoku])\nsolution_sudoku.argmax(-1)+1","metadata":{"execution":{"iopub.status.busy":"2023-12-26T07:27:44.737036Z","iopub.execute_input":"2023-12-26T07:27:44.737901Z","iopub.status.idle":"2023-12-26T07:27:45.864886Z","shell.execute_reply.started":"2023-12-26T07:27:44.737859Z","shell.execute_reply":"2023-12-26T07:27:45.864063Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 398ms/step\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"array([[[7, 8, 6, 6, 6, 8, 8, 9, 7],\n        [8, 8, 8, 8, 8, 8, 8, 8, 8],\n        [8, 8, 8, 6, 6, 8, 8, 8, 8],\n        [8, 8, 6, 6, 8, 8, 8, 8, 7],\n        [8, 8, 8, 8, 8, 8, 8, 8, 8],\n        [8, 8, 8, 6, 8, 8, 8, 8, 6],\n        [6, 8, 8, 6, 8, 8, 8, 8, 8],\n        [6, 8, 8, 6, 6, 8, 8, 8, 8],\n        [7, 8, 8, 8, 6, 8, 8, 8, 7]]])"},"metadata":{}}]}]}